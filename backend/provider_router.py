"""\nAI Provider Router\nRoutes requests to OpenAI (default) first, falls back to Gemini when needed\n"""\n\nimport logging\nfrom typing import Dict, Any, Optional, Callable\nfrom enum import Enum\n\nlogger = logging.getLogger(__name__)\n\n\nclass Provider(Enum):\n    GEMINI = "gemini"\n    OPENAI = "openai"\n\n\nclass ProviderRouter:\n    """\n    Routes AI requests to providers with intelligent fallback\n    - Primary: OpenAI GPT-4o-mini (default)\n    - Fallback: Gemini Flash (when OpenAI fails)\n    """\n    \n    def __init__(self, gemini_agent, openai_agent, default_provider: Provider = Provider.GEMINI):\n        self.gemini_agent = gemini_agent\n        self.openai_agent = openai_agent\n        self.default_provider = default_provider\n        self.metrics = {\n            'gemini_calls': 0,\n            'openai_calls': 0,\n            'gemini_errors': 0,\n            'openai_errors': 0,\n            'fallbacks': 0\n        }\n    \n    def route(\n        self,\n        operation: str,\n        openai_func: Callable,\n        gemini_func: Callable,\n        *args,\n        **kwargs\n    ) -> tuple[Any, Provider]:\n        """\n        Execute operation with automatic fallback\n        \n        Args:\n            operation: Name of the operation (for logging)\n            openai_func: Function to call on OpenAI agent\n            gemini_func: Function to call on Gemini agent\n            *args, **kwargs: Arguments to pass to the functions\n            \n        Returns:\n            Tuple of (result, provider_used)\n        """\n        # Try OpenAI first\n        try:\n            logger.info(f"{operation}: Attempting with OpenAI")\n            self.metrics['openai_calls'] += 1\n            result = openai_func(*args, **kwargs)\n            logger.info(f"{operation}: OpenAI succeeded")\n            return result, Provider.OPENAI\n            \n        except Exception as e:\n            error_msg = str(e).lower()\n            self.metrics['openai_errors'] += 1\n            \n            # Check if it's a quota/rate limit error\n            is_quota_error = any(keyword in error_msg for keyword in [\n                'quota', 'rate limit', 'resource exhausted', '429', 'exceeded'\n            ])\n            \n            if is_quota_error:\n                logger.warning(f"{operation}: OpenAI quota exceeded, falling back to Gemini")\n            else:\n                logger.warning(f"{operation}: OpenAI failed ({str(e)}), falling back to Gemini")\n            \n            # Fallback to Gemini\n            try:\n                self.metrics['fallbacks'] += 1\n                self.metrics['gemini_calls'] += 1\n                logger.info(f"{operation}: Attempting with Gemini")\n                result = gemini_func(*args, **kwargs)\n                logger.info(f"{operation}: Gemini succeeded")\n                return result, Provider.GEMINI\n                \n            except Exception as gemini_error:\n                self.metrics['gemini_errors'] += 1\n                logger.error(f"{operation}: Both providers failed. OpenAI: {str(e)}, Gemini: {str(gemini_error)}")\n                raise Exception(f"All providers failed. Last error: {str(gemini_error)}")\n    \n    def call_with_fallback(\n        self,\n        operation: str,\n        gemini_func: Callable,\n        openai_func: Callable,\n        *args,\n        **kwargs\n    ) -> tuple[Any, Provider]:\n        """\n        Execute operation with automatic fallback (legacy method, redirects to route)\n        \n        Args:\n            operation: Name of the operation (for logging)\n            gemini_func: Function to call on Gemini agent\n            openai_func: Function to call on OpenAI agent\n            *args, **kwargs: Arguments to pass to the functions\n            \n        Returns:\n            Tuple of (result, provider_used)\n        """\n        # Redirect to route with OpenAI first\n        return self.route(operation, openai_func, gemini_func, *args, **kwargs)\n    \n    def extract_json(self, prompt: str) -> tuple[Dict[str, Any], Provider]:\n        """Extract JSON with fallback - OpenAI first, Gemini fallback"""\n        return self.route(\n            "extract_json",\n            self.openai_agent.extract_json,\n            self.gemini_agent.extract_json,\n            prompt\n        )\n    \n    def generate_text(self, prompt: str, temperature: float = 0.7) -> tuple[str, Provider]:\n        """Generate text with fallback - OpenAI first, Gemini fallback"""\n        return self.route(\n            "generate_text",\n            self.openai_agent.generate_text,\n            lambda p, t: self.gemini_agent._call_model(\n                self.gemini_agent.flash_model, p, temperature=t\n            ),\n            prompt,\n            temperature\n        )\n    \n    def get_metrics(self) -> Dict[str, int]:\n        """Get usage metrics"""\n        return self.metrics.copy()\n    \n    def health_check(self) -> Dict[str, bool]:\n        """Check health of all providers"""\n        return {\n            'gemini': self.gemini_agent.health_check() if hasattr(self.gemini_agent, 'health_check') else True,\n            'openai': self.openai_agent.health_check() if hasattr(self.openai_agent, 'health_check') else True\n        }\n